<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Towards Expert-level Autonomous Carotid Ultrasonography with Large-scale Learning-based Robotic System">
  <meta name="keywords" content="carotid artery, autonomous robotic ultrasonography, large-scale learning-based decision-making, clinically-oriented evaluation, plaque screening">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Towards Expert-level Autonomous Carotid Ultrasonography with Large-scale Learning-based Robotic System</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
 -->
 
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!--<h1 class="title is-1 publication-title">OVM3D-Det</h1> -->
          <!-- <h1 class="title is-3 publication-title">Learning <span style="color: rgb(38, 195, 38);">Fine-Grained</span> <span style="color: rgb(0, 140, 255);">Class-Agnostic</span> 3D Segmentation<br>without Manual Labels</h1> -->
          <h1 class="title is-3 publication-title">Towards Expert-level Autonomous Carotid Ultrasonography with Large-scale Learning-based Robotic System</h1>
          <!-- <div class="is-size-4"><b>Nature Communications</b></div> -->


          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://scholar.google.com/citations?user=ULmStp8AAAAJ&hl=en">Haojun Jiang</a><sup>1,4†</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=Tlt5xsYAAAAJ&hl=en">Andrew Zhao</a><sup>1†</sup>,</span>
            <span class="author-block">Qian Yang<sup>3†</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=MDq0cTIAAAAJ&hl=en">Xiangjie Yan</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://github.com/tengwang01">Teng Wang</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://www.wyl.cool/">Yulin Wang</a><sup>1</sup>,</span>
            <span class="author-block">Ning Jia<sup>4</sup>,</span>
            <span class="author-block">Jiangshan Wang<sup>1</sup>,</span>
            <span class="author-block">Guokun Wu<sup>1</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=tE1oVQ4AAAAJ&hl=en">Yang Yue</a><sup>1</sup>,</span>
            <span class="author-block">Shaqi Luo<sup>4</sup>,</span>
            <span class="author-block">Huanqian Wang<sup>1</sup>,</span>
            <span class="author-block">Ling Ren<sup>2</sup>,</span>
            <span class="author-block">Siming Chen<sup>2</sup>,</span>
            <span class="author-block">Pan Liu<sup>2</sup>,</span>
            <span class="author-block">Guocai Yao<sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=rw6vWdcAAAAJ&hl=en">Shiji Song</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com.sg/citations?hl=zh-CN&user=6EIX-JQAAAAJ">Xiang Li</a><sup>1</sup>,</span>
            <span class="author-block">Kunlun He<sup>2*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=-P9LwcgAAAAJ&hl=en">Gao Huang</a><sup>1,4*</sup></span>
          </div>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Department of Automation, Tsinghua University, Beijing, China,</span>
            <span class="author-block"><sup>2</sup>Chinese PLA General Hospital, Beijing, China,</span>
            <span class="author-block"><sup>3</sup>Air Force Characteristic Medical Center, Beijing, China,</span>
            <span class="author-block"><sup>4</sup>Beijing Academy of Artificial Intelligence, Beijing, China</span>
          </div>
          
          <div class="is-size-6 publication-authors">
            <sup>*</sup>Corresponding author(s)
          </div>
          <div class="is-size-6 publication-authors">
            <sup>†</sup>These authors contributed equally to this work.
          </div>
          <div class="is-size-6 publication-authors">
            contact: jhj20 (at) mails (dot) tsinghua (dot) edu (dot) cn
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2411.15657"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://youtu.be/SEvCJghi6Ng"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/LeapLabTHU/UltraBot"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
                  <!-- <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled="">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a> -->
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://mix3d-demo.nekrasov.dev/segment3d/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Demo</span>
                  </a> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <div class="container is-max-desktop">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Abstract</h2>
      <div class="content has-text-justified"> -->

<!-- 

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-four-fifths"> -->
      <div class="column">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Carotid ultrasound requires skilled operators due to small vessel dimensions and high anatomical variability, exacerbating sonographer shortages and diagnostic inconsistencies. 
            Prior automation attempts, including rule-based approaches with manual heuristics and reinforcement learning trained in simulated environments, demonstrate limited generalizability and fail to complete real-world clinical workflows.
            Here, we present UltraBot, a fully learning-based autonomous carotid ultrasound robot, achieving human-expert-level performance through four innovations: 
            (1) A unified imitation learning framework for acquiring anatomical knowledge and scanning operational skills;
            (2) A large-scale expert demonstration dataset (247,000 samples, 100 times scale-up), enabling embodied foundation models with strong generalization;
            (3) A comprehensive scanning protocol ensuring full anatomical coverage for biometric measurement and plaque screening; 
            (4) The clinical-oriented validation showing over 90% success rates, expert-level accuracy, up to 5.5× higher reproducibility across diverse unseen populations.
            Overall, we show that large-scale deep learning offers a promising pathway toward autonomous, high-precision ultrasonography in clinical practice.
          </p>
          <img src="./static/images/intro.jpg" class="teaser-fig" alt="teaser-fig." />
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>



<!-- <section class="section" id="Demo">
  <div class="container is-max-desktop content has-text-centered">
    <h2 class="title">Demo</h2>
    <video controls style="width: 100%; height: auto;">
      <source src="static/video/Subject2_Demo_Speed2_new_0508.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>
</section> -->

<section class="section" id="Demo">
  <div class="container is-max-desktop content has-text-centered">
    <h2 class="title is-3">Demo</h2>

    <!-- Demo 1 -->
    <h3 class="title is-4">Subject 1 (Gender: male, Age: 62, BMI: 23.84)</h3>
    <video controls style="width: 100%; height: auto;">
      <source src="video/Subject1_Demo_Speed2_new_0508.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>

    <!-- Demo 2 -->
    <h3 class="title is-4">Subject 2 (Gender: male, Age: 65, BMI: 19.59)</h3>
    <video controls style="width: 100%; height: auto;">
      <source src="video/Subject2_Demo_Speed2_new_0508.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>

    <!-- Demo 3 -->
    <h3 class="title is-4">Subject 3 (Gender: female, Age: 67, BMI: 19.57)</h3>
    <video controls style="width: 100%; height: auto;">
      <source src="video/Subject3_Demo_Speed2_new_0508.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <!-- Exp. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Results</h2>


        <h3 class="title is-4">Autonomous end-to-end carotid artery ultrasound examination process visualization</h3>
        <img src="./static/images/result2.jpg"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <div class="content has-text-justified">
          <p>
            <strong>(a)</strong> Scanning process in a 65-year-old patient with plaque, yielding high-quality transverse and longitudinal views with clear plaque visibility.
            <strong>(b)</strong> Image analysis of acquired scans, including biometric measurements, plaque segmentation, and color/pulse Doppler.
            <strong>(c)</strong> Representative report summarizing scanning and analysis results.
            <strong>(d)</strong> Representative plaque segmentation results of patients. The term “CCA”, “ICE”, “ECA”, “PMH”, “PSV”, “EDV”, “RI” refer to the common carotid artery, internal carotid artery, external carotid artery, past medical history, peak systolic velocity, end diastolic velocity, and resistive factor respectively.
          </p>
        </div>


        <h3 class="title is-4">Autonomous system evaluation results on unseen human subjects</h3>
        <img src="./static/images/result1.jpg"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <div class="content has-text-justified">
          <p>
            <strong>(a)</strong> Hypothesis test of results consistency between of autonomous system and sonographers. 
            <strong>(b)</strong> Testing the reproducibility of measurements of the CIMT (first row) and CALD (second row) between the robot system and sonographers, evaluated by the SCC, ICC, CV, and MAD. 
            <strong>(c)</strong> Success rate of the robot system on volunteers.
            <strong>(d)</strong> Robustness of the robotic system across variations in age, BMI, machine type, and imaging parameters.
            <strong>(e)</strong> Bland-Altman plot assessing the consistency between lumen diameter and intima-media thickness measurements from the robot system and sonographers.
            <strong>(f)</strong> Comparison of the total time taken for scanning and measurement by the robot system and sonographers, as well as a comparison of just the measurement time.
            <strong>(g)</strong> Volunteers' subjective comfort perceptions under the operation of the robot system and sonographers.
            <strong>(h)</strong> Contact force in the Z-axis (up and down) direction between the transducer and the human neck during the scanning process.
          </p>
          
        </div>


        <!-- <h3 class="title is-4">Intelligent action decision and interpretable biometric measurement with deep neural networks </h3>
        <img src="./static/images/result3.jpg"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <div class="content has-text-justified">
          <p>
            <strong>(a)</strong> Comparison of performance between deep learning and non-deep learning method (k-nearest neighbors) in scanning action decision, as well as between instant and delayed decision-making.
            <strong>(b)</strong> Performance trends in action decision, biometric measurement, and plaque segmentation as training data scales up.
            <strong>(c)</strong> Comparison of the ROC curves for the models of stage transition, action decision, and their combined decision-making in accurately identifying the anatomical structures at the termination positions of each stage.
            <strong>(d)</strong> Performance of the model that predicts whether visible arterial wall and intimal structures exist in the longitudinal section images.
            <strong>(e)</strong> Precision-Recall curve of the model in detecting the local region that can be used to measure the arterial structural parameters.
            <strong>(f)</strong> Our interpretable biometric measurement solution compared with two other non-interpretable baseline models. 
            The t-test was used to check whether the mean error of our method's results is significantly smaller than that of Baseline 2.
            The models were evaluated on 1076 annotated images.
            This boxplot displays standard elements: the box represents the interquartile range (IQR), the central line marks the median, and the whiskers extend to 1.5×IQR.
          </p>
          
        </div>

        <h3 class="title is-4">Precise plaque segmentation with deep neural networks and visualizations </h3>
        <img src="./static/images/result4.jpg"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <div class="content has-text-justified">
          <p>
            <strong>(a)</strong> Comparisons with the existing segmentation models on the test set (best result in bold).
            <strong>(b)</strong> Precision-Recall curve for vascular region detection to guide plaque segmentation.
            <strong>(c)</strong> Visual comparison of plaque prediction results between our method and other approaches.
            <strong>(d, e, f)</strong> The visualization results for determining the presence of clear structures, localizing the measurement position, and the final anatomical keypoint prediction, respectively.
          </p>          
        </div> -->


      </div>
    </div>
    <!--/ Exp. -->
  </div>
</section>



<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{huang2024training,
          title={Training an Open-Vocabulary Monocular 3D Detection Model without 3D Data},
          author={Rui Huang and Henry Zheng and Yan Wang and Zhuofan Xia and Marco Pavone and Gao Huang},
          booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
          year={2024},
          url={https://openreview.net/forum?id=EFkw0OgZOr}
      }</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <!-- <div class="column is-8"> -->
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            It borrows the source code of <a
              href="https://nerfies.github.io/">this website</a>,
              We sincerely thank <a
              href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      <!-- </div> -->
    </div>
  </div>
</footer>

</body>
</html>
